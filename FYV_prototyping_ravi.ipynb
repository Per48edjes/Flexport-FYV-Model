{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FYV Model Prototyping\n",
    "Ravi Dayabhai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "RANDOM_STATE = 614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from modules import load, custom, pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import\\\n",
    "    StandardScaler, OneHotEncoder,RobustScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.metrics import explained_variance_score, max_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target variable\n",
    "TARGET_VARIABLE = 'invoice_total_revenue'\n",
    "\n",
    "# Model training switch\n",
    "TRAINING_SWITCH = False\n",
    "\n",
    "# Train-test split\n",
    "TEST_PCT = .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load.load_data('./queries/first_year_transactions.sql')\n",
    "raw_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "df = load.clean_data(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect cleaned data summary\n",
    "meta_df = pd.concat([df.dtypes.rename('types'), \n",
    "                     df.isnull().mean().rename('missing_data'), \n",
    "                     df.nunique(dropna=False).rename('cardinality'),\n",
    "                     df.var().rename('var')\n",
    "                    ], \n",
    "                    axis=1).sort_values('missing_data', ascending=False)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "**THIS SECTION IS INCOMPLETE.**\n",
    "\n",
    "TODO: I plan on returning to do EDA on my own once I've set up the downstream pipeline properly. In the interim, I'm leaning on Danny's insights from his EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "pr = ProfileReport(df)\n",
    "pr.to_file(output_file=\"./data/df_profile.html\")\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable\n",
    "\n",
    "On the face of it, costs and revenues tend to track one another and net revenue is the difference of these (as we should expect):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement = df[['segment',\n",
    "                       'bill_total_sans_passthrough', \n",
    "                       'invoice_total_revenue', \n",
    "                       'actual_net_revenue']]\n",
    "(income_statement['actual_net_revenue'] - (income_statement['invoice_total_revenue'] - income_statement['bill_total_sans_passthrough'])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement.corr()['actual_net_revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Danny mentioned, this is likely due to the bulk discounting (lower take rate) for our larger clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate feature columns\n",
    "feature_cols = df.columns.difference(['bill_total_sans_passthrough', \n",
    "                                      'invoice_total_revenue', \n",
    "                                      'actual_net_revenue'])\n",
    "feature_df = df[feature_cols]\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features from target\n",
    "X, y = pipeline.data_prep(df, target_feature=TARGET_VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=TEST_PCT, \n",
    "                                                    stratify=X['segment'], \n",
    "                                                    random_state=RANDOM_STATE)\n",
    "print(f\"Training data (train + CV) dimensions: {X_train.shape}\")\n",
    "print(f\"Testing data (true hold-out) dimensions: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features by transforms\n",
    "FUNC_TRANSFORM_FEATURES = ['raw_piers_estimated_commodity_value']\n",
    "PREENCODED_FEATURES = ['import_or_exporter_Exporter', 'import_or_exporter_Importer']\n",
    "\n",
    "# Function transform\n",
    "func_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('func', FunctionTransformer(validate=True))\n",
    "])\n",
    "\n",
    "# Define transforms on numeric, non-function transformed, non-indicators\n",
    "numeric_features = X.select_dtypes(np.number).columns[~X.select_dtypes(np.number).columns.isin(PREENCODED_FEATURES + FUNC_TRANSFORM_FEATURES)]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# Define transforms on categorical types\n",
    "categorical_features = X.select_dtypes(['object', 'category', 'bool']).columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('zero_var', pipeline.ZeroVariance(near_zero=True)),\n",
    "    ('correlation', pipeline.FindCorrelation(threshold=0.9)),\n",
    "])\n",
    "\n",
    "# Construct ColumnTransformer object\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('func_transf', func_transformer, FUNC_TRANSFORM_FEATURES),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Transformation\n",
    "\n",
    "The following dataframe is the output of running the preprocessing column transformation on `X_test`. **Note**: This is *not* necessarily the dataframe that is passed to the predictor since we are doing a GridSearch over the *entire* pipeline process (i.e., transformation + model selection/tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transformed data\n",
    "pp_array = preprocessor.fit_transform(X_train, y_train)\n",
    "transformed_df = pd.DataFrame(pp_array)\n",
    "\n",
    "# Recover column labels from transformers\n",
    "enc_categorical_features = preprocessor.transformers_[2][1]['correlation'].get_feature_names(\n",
    "    preprocessor.transformers_[2][1]['zero_var'].get_feature_names(\n",
    "        preprocessor.transformers_[2][1]['onehot'].get_feature_names(categorical_features)\n",
    "    )\n",
    ")\n",
    "\n",
    "enc_numeric_features = preprocessor.transformers_[1][1]['poly'].get_feature_names(numeric_features)\n",
    "\n",
    "transformed_df.columns = FUNC_TRANSFORM_FEATURES + list(enc_numeric_features) + list(enc_categorical_features) + PREENCODED_FEATURES\n",
    "\n",
    "# Preview transformed data\n",
    "print(transformed_df.shape)\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that features aren't duped in transformation\n",
    "assert len(set(transformed_df.columns)) == transformed_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training pipeline\n",
    "if TRAINING_SWITCH:\n",
    "\n",
    "    # Gridsearch hyperparameter values\n",
    "    param_grid = [\n",
    "  \n",
    "        # Linear models\n",
    "        {'predictor__regressor': [LinearRegression()],\n",
    "         'preprocess__num__poly__degree': [1,2],\n",
    "         'preprocess__func_transf__func__func': [None, np.sqrt]\n",
    "        },\n",
    "        \n",
    "        {'predictor__regressor': [LinearRegression()],\n",
    "         'preprocess__num__poly__degree': [1,2],\n",
    "         'preprocess__func_transf__func__func': [None, np.sqrt],\n",
    "         'predictor__func': [np.log],\n",
    "         'predictor__inverse_func': [np.exp],\n",
    "        },\n",
    "        \n",
    "        {'predictor__regressor': [Ridge()],\n",
    "         'preprocess__num__poly__degree': [1,2],\n",
    "         'preprocess__func_transf__func__func': [None, np.sqrt],\n",
    "         'predictor__regressor__alpha': [0.1, 0.5, 1, 2, 5, 10]\n",
    "        },\n",
    "        \n",
    "        {'predictor__regressor': [Ridge()],\n",
    "         'preprocess__num__poly__degree': [1,2],\n",
    "         'preprocess__func_transf__func__func': [None, np.sqrt],\n",
    "         'predictor__regressor__alpha': [0.1, 0.5, 1, 2, 5, 10],\n",
    "         'predictor__func': [np.log],\n",
    "         'predictor__inverse_func': [np.exp]\n",
    "        },\n",
    "\n",
    "        # Non-linear models\n",
    "        {'predictor__regressor': [AdaBoostRegressor()],\n",
    "         'predictor__regressor__learning_rate': [.01, .1, 1],\n",
    "         'preprocess__num__scaler': [None]\n",
    "        },\n",
    "\n",
    "        {'predictor__regressor': [RandomForestRegressor()],\n",
    "         'predictor__regressor__min_samples_split': [.05, .10, .25],\n",
    "         'preprocess__num__scaler': [None]\n",
    "        },\n",
    "        \n",
    "        # Compare results to naive model\n",
    "        {'predictor': [DummyRegressor(strategy='mean')]\n",
    "        }\n",
    "\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Feature selection and model selection pipeline\n",
    "    model_build_pipe = Pipeline([\n",
    "        \n",
    "        # Do preprocessing\n",
    "        ('preprocess', preprocessor),\n",
    "        \n",
    "        # Reduce dimensions\n",
    "        ('dim_reduce', 'passthrough'),\n",
    "        \n",
    "        # Tune hyperparameters\n",
    "        ('predictor', TransformedTargetRegressor())\n",
    "        \n",
    "    ], verbose=False)\n",
    "\n",
    "    # Do hyperparamter grid search over entire pipeline\n",
    "    model = GridSearchCV(model_build_pipe, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring='r2', \n",
    "                         cv=5,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=3,\n",
    "                         return_train_score=True)\n",
    "\n",
    "    ## Train model & get best parameters and scores\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "else:\n",
    "    model = load.model_loader('models/invoice_total_revenue_model (2020-07-20 20:49:00.268103).skmodel')\n",
    "\n",
    "# See model results\n",
    "model_results = pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "ignore_cols = custom.substring_list_match(model_results.columns, ['time'])\n",
    "model_results.drop(columns=ignore_cols).sort_values(['rank_test_score']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all models returned results\n",
    "display(model_results[model_results['mean_test_score'].isnull()])\n",
    "assert model_results['mean_test_score'].notnull().all(), \"Some models failed to run: check model and transformation specs!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test best fit model predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View best model\n",
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various evaluation metrics on model\n",
    "r2, max_err = r2_score(y_test, y_pred), max_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R^2: {r2}\")\n",
    "print(f\"Max Error: {max_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(model.best_estimator_, X_test, y_test, cv=3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, predicted, alpha=0.3)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4, alpha=0.8)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Archiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to save model\n",
    "SAVER_SWITCH = False\n",
    "if SAVER_SWITCH:\n",
    "    prefix = y.name + '_model '\n",
    "    load.model_saver(model, custom_prefix=prefix)\n",
    "    model_results.to_csv(f\"./models/cv_results/{y.name}_model ({datetime.datetime.now()}).csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
